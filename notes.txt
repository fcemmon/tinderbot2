X- retrying when timeout error only
X- marking profileVerificationRequired and not allowing job to be run with that status

- silent failure, running when its not actually running
- keep track of the likes amount, and matches. mark shadowbanned if does not decrease after x swipes
- add ability to cancel jobs
- only allow jobs created with profile ID
- save runs separately than jobs

# failure Job 133

- run the jobs inside of docker
- connect docker to the database
- this provides isoloation
- this makes the entire system more robust

how do I tell if the job is running or not?
list all the running pods
create a job pod

- list all the running jobs
- create a job
- stop a job
- edit a job's target
- save the jobs logs to a folder by ID
> - connect to the port on a specified port (10-50 workers at a time)
> - this may be something that's requested on demand instead

A job == a worker queue
A job has a static port
A job never fails
A k8job picks off a job ID from the queue and runs it using SKIP LOCKED

- each person has 3 queues

Run persistent docker containers
Put jobs in the queue
Have each container continually run jobs
They should never fail completely

This would put the responsibility on each node worker


1. each job is run in a container
    1a. use kubernetes jobs as worker queues (job never dies)
    2a. each swipe job == a k8s job
2. (deployment) runs a worker queue dedicated to a single browser


- each user has their own namespace

limit the number of jobs that can run
https://stackoverflow.com/questions/71036676/how-to-limit-the-amount-of-simultaneously-running-jobs-of-a-certain-type

cancel running jobs
list all the running jobs
kill/cancel running job

each user has a namespace
each namespace has a resource quota
list all the running jobs

deployment
job

- make sure the jobs can:
- be viewed
- be created
- be cancelled
- be restarted

ancillary:
- logs
- screenshots
- VNC

- either exit 0 or 2 to retry
- mark status appropriately
- track retries or not


#### humanization
https://github.com/Xetera/ghost-cursor

#### onlyfans
https://github.com/skeetzo/onlysnarf

#### tinder
https://github.com/stanfortonski/Tinder-Bot

#### browsers
https://github.com/angrykoala/awesome-browser-automation
https://github.com/puppeteer/replay

#### python
https://github.com/pyppeteer/pyppeteer
https://github.com/cobrateam/splinter
https://github.com/vincentbavitz/bezmouse

#### mouse movement
https://github.com/vincentbavitz/bezmouse

#### google
https://github.com/hongkiat/autologinbot/
https://github.com/chromedp/chromedp

#### scraping
https://github.com/ulixee/secret-agent

#### GUI automation
https://github.com/repeats/Repeat/wiki
https://github.com/RaiMan/SikuliX1
https://github.com/asweigart/pyautogui
https://github.com/intra2net/guibot

### nocode
https://www.browse.ai/
https://www.scrapingbee.com/journey-to-one-million-arr/
https://runninginproduction.com/podcast/62-browserless-gives-you-fast-scalable-and-reliable-browser-automation

### puppeteer
https://github.com/berstend/puppeteer-extra
https://github.com/jsoverson/hackium

### information
https://incolumitas.com/2021/10/16/7-different-ways-to-detect-proxies/
https://geekflare.com/understanding-proxy-types/
https://incolumitas.com/2021/05/20/avoid-puppeteer-and-playwright-for-scraping/
https://incolumitas.com/2021/11/03/so-you-want-to-scrape-like-the-big-boys/

### AI
https://github.com/SerpentAI/SerpentAI

### screencapture
https://pythonguides.com/python-screen-capture/

### bot detection
https://datadome.co/bot-management-protection/detecting-headless-chrome-puppeteer-extra-plugin-stealth/


### operating systems
https://github.com/sickcodes/Docker-OSX

https://scrapeowl.com/

###  proxies
https://scrapingdog.com/
Smart Proxies
https://scrapfly.io/
scrapingbee.com


https://chrome-automation.com/

https://www.bardeen.ai/tutorials/scraper

https://github.com/crisdosyago/BrowserBox

https://automatio.co/


# proxy service
https://brightdata.com/proxy-types/residential-proxies
https://www.webshare.io/
rsocks.net
https://stormproxies.com/
https://proxiware.com/
https://webshare.io/
http://sockshub.io/

# mobile proxy service
https://proxidize.com/
https://oxylabs.io/products/mobile-proxies
https://mobinet.io/
https://coronium.io/
https://metrow.com/social-media-proxies/instagram-proxies/

https://medium.com/@xianghangmi/resident-evil-understanding-residential-ip-proxy-as-a-dark-service-dea9010a0e29
https://www.blackhatworld.com/seo/looking-for-mobile-proxy-4g-of-russia-ukraine-dedicated-sim-card.1385895/


jarvee - social media automation software

## fingerprinting
https://bot.incolumitas.com/#:~:text=more%20sources%2Finformation
https://bot.incolumitas.com/
https://abrahamjuliot.github.io/creepjs/
https://github.com/niespodd/browser-fingerprinting

## check fingerprint/browser
https://browserleaks.com/

https://www.scrapingbee.com/?fpr=darius82

# web scraping API w/ rotating proxies built in
https://apilayer.com/marketplace/description/adv_scraper-api

https://simplescraper.io/

# browsers
https://anty.dolphin.ru.com/cn/
https://www.techstrange.com/anti-browser-is-better-than-vpn/
https://www.blackhatworld.com/seo/dolphin-anty-a-modern-antidetect-browser-10-free-profiles-for-everyone.1350973/

## ip rep
https://www.ipqualityscore.com/ip-reputation-check

## IP detection
https://focsec.com/

# instagram scraping automation
https://apify.com/zuzka/instagram-profile-scraper#features

# proxy detection
https://ip2proxy.com/

https://focsec.com/

## burner card
privacy.com https://news.ycombinator.com/item?id=30724674
prepaid credit cards

https://www.blackhatworld.com/seo/dolphin-anty-a-modern-antidetect-browser-10-free-profiles-for-everyone.1350973/

## sms
https://www.textverified.com/

## profile verification
https://github.com/sensity-ai/dot
https://github.com/alievk/avatarify-desktop

# robert proxy
https://iproyal.com/?r=92381

# discussion
https://www.blackhatworld.com/

## emulator
LDplayer emulator

# chatbots
https://github.com/polakowo/gpt2bot
https://github.com/gunthercox/ChatterBot

https://news.ycombinator.com/item?id=29062008
abadger9 6 months ago | parent | context | favorite | on: Avoiding bot detection: How to scrape the web with...
I'm a lead engineer on the search team of a publicly traded company who's bread and butter is this domain. I was curious about this list, it candidly misses the mark- the tech mentioned in this blog is what you might get if you hired a competent consultant to build out a service without having domain knowledge. In my experience, what's being used on the bleeding edge is two steps ahead of this.
============================================================================
gzer0 6 months ago | parent | next [–]

I have a considerable amount of experience in the industry.
Some of these so-called "advanced" techniques:

  * We use our own mobile emulation software (similiar to bluestacks). Turns out, mobile helps with a lot of things (below).
  * We use mobile IPs only. Mobile LTE data users are behind CGNATfor IPV4. You can't block one ip without possibly blocking hundreds of innocent IPs using the same exit point.
  * All you need is a new useragent and browser fingerprint; combined with emulation + mobile IPs, there's really no easy way for companies to block this.
  * With the advent and ease of virtualization; we avoid using any headless browsers. Seriously, if you can, never use headless. This should be close to rule number one for anyone looking to operate any kind of scrapers. All of our scrapers are run in isolated virtual instances with full mobile browsers.
  * We can easily reset our device identifier, device carrier, simulated SIM information, and especially important is the Google advertising ID that is set per device; the list goes on. The key here is #1, our mobile emulation software.
  * Our automation scripts are a combination of human recorded set of actions which we then perfected and can run in certain loops (for some of our data).
===========================================
abc03 6 months ago | prev | next [–]

I scrap government sites a lot as they don't provide apis. For mobile proxies, I use the proxidize dongles and mobinet.io (free, with Android devices). As stated in the article, with cgNAT it's basically impossible to block them as in my case, half the country couldn't access the sites anymore (if you place them in several locations and use one carrier each there).
================================================================
InvOfSmallC 6 months ago | unvote | prev | next [–]

Where I was working we stopped caring about ips browser etc because it was just a race. What we did was analyzing behaviour of clicks and acted on that. When we recognized it we went on serving a fake page. It cuts down a little bit of costs because it was static pages. In general it took a lot of time for them to discover the pattern and it was way more manageable for us.

==================================================================
incolumitas 6 months ago | parent | next [–]

4G proxies are just soo much better than so called "residential" or straight datacenter proxies. It makes sense to create your own 4G proxy farm if you conduct business in that area.
With only 10 dongles and 10 dataplans, you can have a lot of IP addresses that are extremely hard to block. It's an one time investment, paying proxy providers is a fixed cost.
================================================
throwaway984393 6 months ago | unvote | prev | next [–]
If you want to avoid bot detection, learn how bot detection work. A lot of commercial "webapp firewalls" and the like actually have minimum requirements before they flag certain traffic as a botnet; stay below those limits and you can keep hammering away. Sometimes those limits are quite high.
In the past we've had the most success defeating bots by just finding stupid tricks to use against them. Identify the traffic, identify anything that is correlated with the botnet traffic, and throw a monkey wrench at it. They're only using one User Agent? Return fake results. 90% of the botnet traffic is coming from one network source (country/region/etc)? Cause "random" network delays and timeouts. They still won't quit? During attacks, redirect to captchas for specific pages. During active attacks this is enough to take them out for days to weeks while they figure it out and work around it.
